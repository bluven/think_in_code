# 线上大规模数据迁移

标签（空格分隔）： 数据库 迁移 大规模

---
原文： [Online migrations at scale][1]
---

在开发软件的过程中，工程师团队都会遇到一个常见的挑战：他们最终会重新设计数据模型从而支持干净的抽象和更复杂的特性。生产环境下，这意味着要迁移数百万的活动对象（active objects），重构上千行代码。

Stripe用户希望我们的API保持可用性及一致性。这就意味着当我们做迁移时，我们需要极其小心：系统中的对象必须有准确的值，服务也需要一直保持可用性。

在这篇文章中，我们将解释我们是如何安全地对实施一次大的涉及到数以亿计的订阅对象（Subscriptions objects）的迁移。

## 为什么迁移如此困难？

* 规模(Scale)
Stripe有数以亿计的订阅对象。实施一次涉及到这些对象的大迁移对我们的生产数据库来说要做许多事。

假设迁移一条数据需要1秒，在串行的方式下，需要花费3年事件才能迁移1亿条对象。

* 可用时间(Uptime)
Stripe时刻都有业务交易。 我们在线实施基础架构升级，而不是依靠规划好的运维窗口（maintenance windows）。因为我们不能简单地在迁移期间停止订阅服务，必须在服务100%运行的时候执行迁移。

* 准确性(Accuracy)

我们的订阅表（Subscriptions table）在代码库里被多处使用。如果我们尝试改动订阅服务的数千行代码，几乎可以肯定会忽视一些边界情况。我们需要保证每个服务能继续信任准确的数据。

## 一个线上迁移模式
  
  将百万计的对象从一个数据库表移动到另一张表是非常困难的，但许多公司必须做这些事。
  
  人们经常采用一个常见的4步双写模式来实施大规模线上迁移。步骤如下：
  
  1. **两路写入**已存在及新的表，从而保持同步.
  2. 修改代码库里**的所有读出路径**到新表.
  3. 修改**所有的写入路径**到新表。
  4. **删除**所有依赖过时数据模型的**旧数据**.
  
----

## 我们的迁移案例: 订阅

什么是订阅？我们为什么要实施一次迁移？

Stripe订阅帮助DigitalOcean，Squarespace之类的用户构建和管理他们的客户的定期结算。在过去的几年我们已经添加了一些特性来支持他们更复杂的结算模型，例如多重订阅，试验，优惠券及发票。

早些时候，每个客户模型最多只有一个订阅。我们的客户被存为一个单个记录。因为从客户映射到订阅直接简单，订阅数据就与客户数据存在一起。

```ruby
class Customer
  Subscription subscription
end
```

最后我们意识到一些用户想创建有多个订阅的客户。我们决定将订阅字段转变为订阅列表字段————这这使得我们可以保存一个有多个活动订阅列表的数组。

```ruby
class Customer
  array: Subscription subscriptions
end
```
当我们添加更多特性时，这个模型显得有些问题。每次更改一个客户的订阅信息时，就意味着更改整个客户记录和涉及客户对象扫描的订阅查询语句。所以我们决定将订阅数据另存一处。

提醒一下，我们的迁移四步骤是：

  1. **两路写入**已存在及新的表，从而保持同步.
  2. 修改代码库里**的所有读出路径**到新表.
  3. 修改**所有的写入路径**到新表。
  4. **删除**所有依赖过时数据模型的**旧数据**.
  
让我们来看看实践中这四步是怎样的。

## 第一部分： 两路写入

开始迁移时，我们建立了一个新的数据库表。第一步是在复制新信息从而在两个存储都写入新信息。后面我们会在新存储回填缺失的数据，这样两个存储ji了相同的信息。

在我们的案例中，我们会记录新创建的订阅信息到客户表及订阅表。在开始向两个新表写入前，值得考虑一下额外的写操作对生产数据库的性能影响。我们可以通过逐渐提高要复写的对象的百分比来减缓性能问题，同时小心观察运维指标。

这时候新创建的对象存在于两个表中，但旧对象只能在旧表中找到。我们用一种懒惰的方式将现有的订阅数据复制过去：当对象更新的时候他们会被自动复制到新表中。这个方式让我们可以渐渐的转移现有的订阅信息。

最后，我们将剩余的客户订阅信息回填到新订阅表中。

回填实时数据库中的新表中最昂贵的部分就是查找所有需要迁移的对象。通过查询数据库的方式来查找所有对象会发起对生产数据库的查询操作，这会非常耗时。幸运的是，我们将这个工作交给一个对生产数据库不会造成影响的离线过程(offline process)。我们对我们的Hadoop集群可用的数据库做快照，这样就可以用MapReduce快速的以离线，分布式地处理我们的数据。

我们使用Scaling管理我们的MapReduce工作。Scalding是一个非常有用的用Scala开发，简化MapReduce作业编写的库（可以用10行代码写一个简单的作业）。在这种情况下，我们使用Scalding来帮我们识别所有的订阅。步骤如下：

* 写一个Scalding作业，这个作业提供一个所有需要被复制的订阅对象的ID列表。

* Run a large, multi-threaded migration to duplicate these subscriptions with a fleet of processes efficiently operating on our data in parallel.

* 一旦这个迁移完成，再运行一次Scalding作业来确保订阅表没有遗漏现有的订阅信息。
* 
## 第二部分： 改变所有的读取路径

现在新旧数据既然已经一致了，下一步就是开始使用新的数据存储来读取所有的数据。

我们需要确保从新表读取数据是安全的：订阅信息必须一致。我们将使用GitHub的Scientist来核实读取路径。Scientist是一个Ruby库，这个库可以让你运行实验，比较两个不同的代码路径的结果，为生产环境下两个表达式导致不同的结果会发出警告。利用Scientist，我们可以为实时的不同结果生成警告和计量信息。档一个实验代码路径出现错误，其他的应用不会被影响。

我们将运行如下的实验：

* 用Scientist从订阅表和客户表读取信息。
* 如果结果不同，抛出错误警告我们的工程师有不一致的情况。
* 当我们核实所有的数据都匹配，我们开始从新表读取数据。

## 第三部分: 改变所有的写入路径

下一步，我们需要升级写入路径导向新的订阅表。我们的目标是渐进式地改变，所以要采取小心的策略。

目前为止，我们都是将数据写入旧的存储然后再复制到新的存储。

现在我们想反转这个顺序： 先写入新存储，然后归档到旧存储。通过保持两个存储的一致性，我们可以做到渐进地更新并小心观察这些改变。

重构这些更改订阅信息的代码路径大概是这次迁移中最具有挑战性的部分。Stripe处理订阅操作（更新，按比例分配，续订等）的逻辑分散在多个服务中的上千行代码中。

成功重构的关键是渐进式处理：我们尽可能地将许多代码路径隔离到最小的单元，以便我们可以小心应用变更。我们的两张表需要在每一步都保持一致。

对每一个代码路径，我们需要使用一种整体的方式来确保我们的改变是安全的。我们不能仅仅是用新记录替换旧记录：逻辑的每一片都需要仔细考虑。任何一处遗漏都有可能导致数据不一致。谢天谢地，我们可以运行更多的Scientist实验来警告我们任何潜在的不一致之处。

Our new, simplified write path looks like this:

当这个属性被调用时，通过抛错，我们可以确保没有代码块继续使用过期的订阅数组：

```ruby
class Customer
  def subscriptions
    hard_assertion_failed("Accessing subscriptions array on customer")
  end
end
```

## 第四部分： 删除旧数据

我们的最后（以及最令人满意的）步骤是去除写入旧存储的代码并最终删除他们。

一旦我们确定了没有代码依赖过时的数据模型的订阅字段，我们就不再需要写入旧表：

随着这个改变，我们的代码不在使用旧的存储，新表现在成为我们的唯一可信来源。

我们现在可以去掉客户对象上的订阅列表，并用一种渐进的方式进行删除。首先我们在订阅信息加载的时候自动清空这个数组，然后运行一个最终Scalding作业和迁移来查找需要删除的任何遗留对象。最后我们得到的数据模型如下：

## 总结

在保持Stripe API一致的同时运行迁移是复杂的。如下步骤帮助我们安全地运行：

* 我们安排了一个4阶段迁移策略，该策略允许我们在转移数据的同时运营我们的生产环境的服务而无需下线。
* 用Hadoop离线处理数据，使得我们可以用MapReduce以并发的方式管理大容量数据，而不是依赖昂贵的生产数据库查询操作。
* 我们做的所有修改都是渐增的。我们从未尝试过一次性改动几百行代码。
* 我们的所有改动都是高度透明且可查看的。Scientist实验在一条生产数据不一致的时候尽快地警告我们。过程中的每一步，随着安全的迁移，我们都获取了自信。

我们发现这种方式在Stripe我们执行的许多线上迁移都很有效。我们希望这些实践可以帮助在其他实施大规模迁移的团队。


  [1]: https://stripe.com/blog/online-migrations
  



